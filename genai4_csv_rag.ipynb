{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMdV8kAq81YN10IV0B0Goqw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c0f36995ee384382911756759e09a980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_242ad5b072784109954287083cfba198",
              "IPY_MODEL_8bb84fbd84594a3b91211071959694e5",
              "IPY_MODEL_2a5e30cc609b4cc6a14d51c42c6d585b"
            ],
            "layout": "IPY_MODEL_06bcce3b564743b89016d3d2327b2279"
          }
        },
        "242ad5b072784109954287083cfba198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_487226861b124ea3a85a83b0bf517061",
            "placeholder": "​",
            "style": "IPY_MODEL_a313a9946d284bdd8edf6b5db8ca80c3",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "8bb84fbd84594a3b91211071959694e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c1aa266f01f45c5b6cd2634799c8532",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e71654f6580e44a9946b44459e0f1bcc",
            "value": 8
          }
        },
        "2a5e30cc609b4cc6a14d51c42c6d585b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cddf6cd0e5bc4ab29f20edf1f6b341de",
            "placeholder": "​",
            "style": "IPY_MODEL_1e6547d708db4df2b07f1ff3eb0bd0f0",
            "value": " 8/8 [01:04&lt;00:00,  7.01s/it]"
          }
        },
        "06bcce3b564743b89016d3d2327b2279": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "487226861b124ea3a85a83b0bf517061": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a313a9946d284bdd8edf6b5db8ca80c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c1aa266f01f45c5b6cd2634799c8532": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e71654f6580e44a9946b44459e0f1bcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cddf6cd0e5bc4ab29f20edf1f6b341de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e6547d708db4df2b07f1ff3eb0bd0f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vishwa0703/GenAI/blob/main/genai4_csv_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMsuty36hcIA",
        "outputId": "b54ceb3d-16cb-47d1-bbd7-9d715d5abf9a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Workaround to avoid following error at notebook\n",
        "# Error: NotImplementedError: A UTF-8 locale is required. Got ANSI_X3.4-1968\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "S_TMoGrskofz"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Huggingface libraries to run LLM.\n",
        "!pip install -q -U transformers==4.40.2\n",
        "!pip install -q -U accelerate==0.30.1\n",
        "!pip install -q -U bitsandbytes==0.43.1\n",
        "!pip install -q -U huggingface_hub==0.23.0\n",
        "\n",
        "#LangChain related libraries\n",
        "!pip install -q -U langchain==0.1.2\n",
        "!pip install -q -U langchain-community==0.0.38\n",
        "\n",
        "#Open-source pure-python PDF library capable of splitting, merging, cropping,\n",
        "#and transforming the pages of PDF files\n",
        "!pip install -q -U pypdf==4.2.0\n",
        "\n",
        "#Python framework for state-of-the-art sentence, text and image embeddings.\n",
        "!pip install -q -U sentence-transformers==2.7.0\n",
        "\n",
        "# FAISS Vector Databses specific Libraries\n",
        "!pip install -q -U faiss-gpu==1.7.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRheh6soktYj",
        "outputId": "693be1c8-4986-470d-e6ed-896870377ebf"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-text-splitters 0.3.2 requires langchain-core<0.4.0,>=0.3.15, but you have langchain-core 0.1.19 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain 0.1.2 requires langsmith<0.0.84,>=0.0.83, but you have langsmith 0.1.147 which is incompatible.\n",
            "langchain-text-splitters 0.3.2 requires langchain-core<0.4.0,>=0.3.15, but you have langchain-core 0.1.53 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig, BitsAndBytesConfig\n",
        "import torch\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "print(\"Device:\", device)\n",
        "if device == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRx767G6lUVu",
        "outputId": "681fc968-142f-434d-958d-7863d49d6051"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "origin_model_path = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "model_path = \"filipealmeida/Mistral-7B-Instruct-v0.1-sharded\"\n",
        "bnb_config = BitsAndBytesConfig \\\n",
        "              (\n",
        "                load_in_4bit=True,\n",
        "                bnb_4bit_use_double_quant=True,\n",
        "                bnb_4bit_quant_type=\"nf4\",\n",
        "                bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "              )\n",
        "model = AutoModelForCausalLM.from_pretrained (model_path, trust_remote_code=True,\n",
        "                                              quantization_config=bnb_config,\n",
        "                                              device_map=\"auto\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(origin_model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "c0f36995ee384382911756759e09a980",
            "242ad5b072784109954287083cfba198",
            "8bb84fbd84594a3b91211071959694e5",
            "2a5e30cc609b4cc6a14d51c42c6d585b",
            "06bcce3b564743b89016d3d2327b2279",
            "487226861b124ea3a85a83b0bf517061",
            "a313a9946d284bdd8edf6b5db8ca80c3",
            "3c1aa266f01f45c5b6cd2634799c8532",
            "e71654f6580e44a9946b44459e0f1bcc",
            "cddf6cd0e5bc4ab29f20edf1f6b341de",
            "1e6547d708db4df2b07f1ff3eb0bd0f0"
          ]
        },
        "id": "HJUFh20FlXO4",
        "outputId": "d6fd7973-7a01-4572-aabe-9659596ac28c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0f36995ee384382911756759e09a980"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_generation_pipeline = transformers.pipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    task=\"text-generation\",\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    repetition_penalty=1.1,\n",
        "    return_full_text=False,\n",
        "    max_new_tokens=300,\n",
        "    temperature = 0.3,\n",
        "    do_sample=True,\n",
        ")\n",
        "mistral_llm = HuggingFacePipeline(pipeline=text_generation_pipeline)"
      ],
      "metadata": {
        "id": "bAVbN4ywlnQL"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using CSV File with LangChain CSVLoader"
      ],
      "metadata": {
        "id": "ZA2N7ig1nmHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "# Load the CSV file\n",
        "loader = CSVLoader(file_path='/content/drive/MyDrive/Colab Notebooks/greenhouse_gas_inventory_data_data.csv')\n",
        "data = loader.load()\n",
        "\n",
        "# Split the documents into smaller chunks\n",
        "#separator=\"\"\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "chunked_docs  = text_splitter.split_documents(data)\n",
        "\n",
        "# Using HuggingFace embeddings\n",
        "embeddings = HuggingFaceEmbeddings()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Msvnc7al4vQ",
        "outputId": "268c667f-9b74-4f31-a210-9202dca12187"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "db = FAISS.from_documents(chunked_docs,\n",
        "                          HuggingFaceEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2'))\n",
        "\n",
        "\n",
        "# Connect query to FAISS index using a retriever\n",
        "retriever = db.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={'k': 4}\n",
        ")\n",
        ""
      ],
      "metadata": {
        "id": "Wg_nBNOumjkq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Conversational Retrieval Chain\n",
        "qa_chain = ConversationalRetrievalChain.from_llm(mistral_llm, retriever,return_source_documents=True)"
      ],
      "metadata": {
        "id": "5d7fsfcInqxU"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We will run an infinite loop to ask questions to LLM and retrieve answers untill the user wants to quit\n",
        "import sys\n",
        "chat_history = []\n",
        "query = input('Prompt: ')\n",
        "# Ask question related CSV file like Which country has highest green gas?\n",
        "result = qa_chain.invoke({'question': query, 'chat_history': chat_history})\n",
        "print('Answer: ' + result['answer'] + '\\n')\n",
        "chat_history.append((query, result['answer']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLqzy4SdnD2i",
        "outputId": "a1ce76bb-4da2-442c-f9a2-5ffa2527c91f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: brief  of australia data\n",
            "Answer:  Australia's greenhouse gas emissions in kilotonne CO2 equivalent increased from 418,674.1 kilotonne CO2 equivalent in 1991 to 491,441.7 kilotonne CO2 equivalent in 2001. In 1991, Australia emitted 133.2 kilotonne CO2 equivalent of hydrofluorocarbons (HFCs). In 1990, Australia emitted 142.5 kilotonne CO2 equivalent of HFCs.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using CSV file with Pandas dataframe"
      ],
      "metadata": {
        "id": "zGFQpx16oGMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U pandas==2.0.3"
      ],
      "metadata": {
        "id": "uMxWtauGrAW_"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Load the CSV file\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/greenhouse_gas_inventory_data_data.csv')"
      ],
      "metadata": {
        "id": "r6w-1R1TrGK1"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema.document import Document\n",
        "text = \"\"\n",
        "for ind in df.index:\n",
        "    text += f\"{df['country_or_area'][ind]}  {df['year'][ind]}  {df['value'][ind]}\\n#####\\n\"\n",
        "#Converting text to LangChain documents so that StuffDocumentsChain can understand Input\n",
        "documents = Document(page_content=text, metadata={\"source\": \"local\"})"
      ],
      "metadata": {
        "id": "lZmwoOKnrL5f"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "# Split the documents into smaller chunks\n",
        "#separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0, separators=\"[#####]\")\n",
        "chunked_docs  = text_splitter.split_documents([documents])\n",
        "\n",
        "# Using HuggingFace embeddings\n",
        "embeddings = HuggingFaceEmbeddings()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_vlsGgjrgrq",
        "outputId": "b2035393-5cbb-4016-db48-12438cfa7b0e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "db = FAISS.from_documents(chunked_docs,\n",
        "                          HuggingFaceEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2'))\n",
        "\n",
        "\n",
        "# Connect query to FAISS index using a retriever\n",
        "retriever = db.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={'k': 4}\n",
        ")"
      ],
      "metadata": {
        "id": "EQgCxI83rvpb"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Conversational Retrieval Chain\n",
        "qa_chain = ConversationalRetrievalChain.from_llm(mistral_llm, retriever,return_source_documents=True)"
      ],
      "metadata": {
        "id": "ZUOUWcVZrzPr"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We will run an infinite loop to ask questions to LLM and retrieve answers untill the user wants to quit\n",
        "import sys\n",
        "chat_history = []\n",
        "query = input('Prompt: ')\n",
        "# Ask question related CSV file like Which country has highest green gas?\n",
        "result = qa_chain.invoke({'question': query, 'chat_history': chat_history})\n",
        "print('Answer: ' + result['answer'] + '\\n')\n",
        "chat_history.append((query, result['answer']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-4BumVur2sq",
        "outputId": "65d3db5a-89c8-427e-be85-24a7c748dd87"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: brief  of australia data\n",
            "Answer:  Australia has a population of approximately 24 million people and is located in the southern hemisphere. The country is known for its unique wildlife, diverse landscapes, and strong economy. It is also a popular tourist destination, with attractions such as Sydney Opera House, Great Barrier Reef, and Uluru.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}